{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l96XD2NrEUip"
   },
   "source": [
    "# 基盤DS演習 第3回\n",
    "\n",
    "※本演習資料の二次配布・再配布はお断り致します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uKYoJWWrDGj"
   },
   "source": [
    "　今回の演習の内容は以下の3つである。\n",
    "\n",
    "**DS3.0 | データクレンジング：データの整理**\n",
    "\n",
    "**DS3.1 | 決定木 (decision tree) を用いた分類**\n",
    "\n",
    "**DS3.2 | モデル選択 (model selection)**\n",
    "\n",
    "　今回から、pandas や numpy に加えて機械学習用ライブラリである scikit-learn を用いて決定木を構築していく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv_jpkJu7PPe"
   },
   "source": [
    "## DS3.0 | データクレンジング：データの整理\n",
    "\n",
    "　今回は、タイタニック号の乗客のデータ `DS3_titanic.csv` を用いて、沈没事故の際にどのような乗客が生き残ったのかを予測する。\n",
    "実はこの `DS3_titanic.csv` 、用いるデータの情報に一部抜けが存在しているため、まず**データクレンジング**と呼ばれる作業を行う（**補足資料 ※1**）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0L67TrVCMkA"
   },
   "source": [
    "　まず、OCW-iから `DS3_titanic.csv` を取得し、**`DS3_titanic.csv` をGoogle Colaboratoryにアップロードする**。アップロードが終わったら、どんな情報が含まれているデータなのか見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WIGknYHNCamq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"DS3_titanic.csv\")\n",
    "pd.set_option(\"display.max_columns\", None) # 全ての列を表示するための設定\n",
    "print(df.head())                           # 最初の5データのみを表示する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7SoinkMtSe2"
   },
   "source": [
    "　このデータには、生き残ったかどうかを示す`Survived`と、各乗客の情報が記されている。\n",
    "\n",
    "　今回は簡単のために、乗客の情報は`Pclass`, `Sex`, `Age`, `Fare`の4種類のみを説明変数 (explanatory variables) として使うことにして、細かく見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uVGhVhFfvJ0M"
   },
   "outputs": [],
   "source": [
    "# dfの中身を書き換えずにXを書き換える場合は.copy()を付ける\n",
    "X = df[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].copy() # attributes (explanatory variables)\n",
    "y = df[\"Survived\"] # class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVOLpa18_e14"
   },
   "source": [
    "　まず、ほとんどの機械学習のモデルは説明変数や目的変数 (class label) を**数値**で受け取るので、性別を数値に変換する。このデータでは性別は2種類しかないので、0/1の2値に変換しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v3HkXI1eA8Cs"
   },
   "outputs": [],
   "source": [
    "# 「\"male\"だったら1、そうでなければ0」という配列を作成し、X[\"Sex\"]に代入する\n",
    "X_sex_new = X[\"Sex\"].apply(lambda x: 1 if x == 'male' else 0) # X[\"Sex\"]自体は書き変わらないので注意 \n",
    "X[\"Sex\"] = X_sex_new                                          # 代入することで書き換える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p_j6KWB81pGF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age     Fare\n",
      "0       3    1  22.0   7.2500\n",
      "1       1    0  38.0  71.2833\n",
      "2       3    0  26.0   7.9250\n",
      "3       1    0  35.0  53.1000\n",
      "4       3    1  35.0   8.0500\n"
     ]
    }
   ],
   "source": [
    "print(X.head()) # Sexが0/1になっていることを確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgIYiDHVBQIu"
   },
   "source": [
    "　次に、明らかな値の間違いがないか確認するために、年齢のヒストグラムを描画してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u_Cm-tU2_eAm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "X[\"Age\"].hist()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0qroBcfAQCY"
   },
   "source": [
    "　最大が0才から80才程度なので、どうやら変な値は入っていないようだ。\n",
    "\n",
    "　次に、全ての説明変数について、値の欠損が存在しないか確認する。以下のコードで実行する `describe()` メソッドは、各数値型の特徴量の記述統計量を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hHngjagEAiFe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Pclass         Sex         Age        Fare\n",
      "count  891.000000  891.000000  714.000000  891.000000\n",
      "mean     2.308642    0.647587   29.699118   32.204208\n",
      "std      0.836071    0.477990   14.526497   49.693429\n",
      "min      1.000000    0.000000    0.420000    0.000000\n",
      "25%      2.000000    0.000000   20.125000    7.910400\n",
      "50%      3.000000    1.000000   28.000000   14.454200\n",
      "75%      3.000000    1.000000   38.000000   31.000000\n",
      "max      3.000000    1.000000   80.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbD-_j2ABcr9"
   },
   "source": [
    "　ここで注目すべきは、**`Age`の`count`が他の件数と異なり、714となっている**。 `describe()` メソッドでは、**欠損していないデータの数**が `count` に表示されるため、年齢情報には欠損値が存在していることを示唆している。\n",
    "\n",
    "　それでは、実際に欠損値を探してみる。値が欠損しているかどうかの判定は`isna()`で行うことができる(IS Not A number の略である)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yttyWnXZCCwp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "886    False\n",
      "887    False\n",
      "888     True\n",
      "889    False\n",
      "890    False\n",
      "Name: Age, Length: 891, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(X[\"Age\"].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9UnY5vfCCB4"
   },
   "source": [
    "　しばしば`True`が表示されており、値の欠損が確かに存在していることがわかる。\n",
    "どんなデータで欠損が発生しているか見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y3Wq_spOCW9l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex  Age     Fare\n",
      "5         3    1  NaN   8.4583\n",
      "17        2    1  NaN  13.0000\n",
      "19        3    0  NaN   7.2250\n",
      "26        3    1  NaN   7.2250\n",
      "28        3    0  NaN   7.8792\n",
      "..      ...  ...  ...      ...\n",
      "859       3    1  NaN   7.2292\n",
      "863       3    0  NaN  69.5500\n",
      "868       3    1  NaN   9.5000\n",
      "878       3    1  NaN   7.8958\n",
      "888       3    0  NaN  23.4500\n",
      "\n",
      "[177 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X[X[\"Age\"].isna()]) # Ageが欠損しているデータを全て抜き出す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7gMebdiCfLI"
   },
   "source": [
    "　多くの学習手法は、全てのデータが埋まりきっていることを前提としているため、欠損値を含むデータを除外する、あるいはこれらの欠損値をなんらかの値で補填する必要がある。\n",
    "\n",
    "　ここでは、（極めて雑な処理なのだが）平均値で年齢を埋めてしまうことにする。欠損値を埋める、という操作は`fillna()`という関数で行うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Skl2HeyVD_3O"
   },
   "outputs": [],
   "source": [
    "ave_age = X[\"Age\"].mean()\n",
    "X[\"Age\"] = X[\"Age\"].fillna(ave_age) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e0YEOBACETYF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Pclass         Sex         Age        Fare\n",
      "count  891.000000  891.000000  891.000000  891.000000\n",
      "mean     2.308642    0.647587   29.699118   32.204208\n",
      "std      0.836071    0.477990   13.002015   49.693429\n",
      "min      1.000000    0.000000    0.420000    0.000000\n",
      "25%      2.000000    0.000000   22.000000    7.910400\n",
      "50%      3.000000    1.000000   29.699118   14.454200\n",
      "75%      3.000000    1.000000   35.000000   31.000000\n",
      "max      3.000000    1.000000   80.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KVessl8EVWa"
   },
   "source": [
    "　これでデータクレンジングが完了した。\n",
    "\n",
    "　最後に、この後の評価の為に、 `X` と `y` を**訓練データ (training data)** と**テストデータ (test data)** に分割する。これは、 scikit-learn の `train_test_split()` 関数が便利である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hEwuvgUBFwIM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "# test_size=0.2とすることで、全データの20%をテストデータにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIQmDTLPGBzt"
   },
   "source": [
    "　これにより、データは**図3.1**のように分割された。\n",
    "\n",
    "![図3.1](http://i.imgur.com/Y1DW99k.png)\n",
    "\n",
    "**図3.1** 訓練データ (training data) とテストデータ (test data) への分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rajyx2GLvo-D"
   },
   "source": [
    "## DS3.1 | 決定木を用いた分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt9Yb4TO7xpc"
   },
   "source": [
    "　決定木 (decision tree) とは、**図3.2**のように、**目的変数をよりキレイに分類できる説明変数と閾値で分岐させ続ける**ことで分類を行うモデルである。一般的には**図3.2**のように、3つ以上にいきなり分岐させることも決定木の範疇だが、これから利用するscikit-learnの決定木は2つに分岐させることにのみ対応している。\n",
    "\n",
    "![図3.2](https://upload.wikimedia.org/wikipedia/ja/5/5d/Decision_tree_model_ja.png)\n",
    "\n",
    "**図3.2** 決定木の例（Wikipedia 「決定木」 より抜粋）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZRigrPyXCSr"
   },
   "source": [
    "### DS3.1.1 | scikit-learnを利用した決定木の構築と予測\n",
    "\n",
    "　決定木は `DecisionTreeClassifier()` という名前で用意されているので、これを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WF8oU4zD7EbP"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rVW_tIqyCeMr"
   },
   "outputs": [],
   "source": [
    "model_full = DecisionTreeClassifier(random_state=0) # 再現性のため乱数のシードを固定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8gzxFKyp7Ag"
   },
   "source": [
    "　上記のコードは見た目上は「`DecisionTreeClassifier()` という関数に `random_state=0` という引数を渡した返り値を `model_full` に格納した」ようになっているが、実際には**決定木を構築するための（からっぽな）モデルを準備して、model_fullという名前を付けた**と考えてほしい。\n",
    "\n",
    "　これに対して、`model_full.fit()` を行うことで、実際に決定木を構築することができる。講義で分割の基準としてジニ係数（不純度、gini impurity）や情報利得 (information gain) を習ったが、ジニ係数を使った決定木の構築がデフォルト値となっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dFXwIpwSp8ry"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full.fit(X_train, y_train) # 訓練データの説明変数と目的変数を引数として与える\n",
    "\n",
    "# 注意：以下のコードは間違い\n",
    "#trained = model_full.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRjgacnGaM1t"
   },
   "source": [
    "　これだけで決定木の構築が完了した。 `model_full` 自体が書き換えられるので、代入を行う必要がないことに注意せよ。\n",
    "\n",
    "　この学習済みモデルに対して、 `model_full.predict()` を行うことで訓練データの予測を行ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ifWHwG0o2g3o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0\n",
      " 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0\n",
      " 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "pred_y_train = model_full.predict(X_train) # 訓練データを予測してみる\n",
    "print(pred_y_train) # 予測結果を表示してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27STsl2Q2nuU"
   },
   "source": [
    "　出力結果は0と1の羅列だが、これは死亡=0、生存=1という意味で、今回説明変数として与えた4種類の情報から予測を行った結果を示している。\n",
    "\n",
    "　次に、実際の生存結果 `y_train` と比較を行い、予測があっていたら `True` 、間違っていたら `False` とするような配列を作成しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eXishslq3BUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140    True\n",
      "439    True\n",
      "817    True\n",
      "378    True\n",
      "491    True\n",
      "       ... \n",
      "835    True\n",
      "192    True\n",
      "629    True\n",
      "559    True\n",
      "684    True\n",
      "Name: Survived, Length: 712, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# NumPy配列の要素単位で結果が一致しているかどうかを比較している\n",
    "prediction_result = (pred_y_train == y_train)\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KuVzTFi3tcV"
   },
   "source": [
    "　非常に `True` が多く、正しく予測できている確率が高そうだ。最後に、正解率（＝ `True` の確率）を計算する。少しトリッキーだが、`True`/`False` の配列の平均値を計算することで、正解率を求めることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MXYIMm8RaYa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9789325842696629\n"
     ]
    }
   ],
   "source": [
    "# np.meanでは、True=1, False=0として解釈されるので\n",
    "# meanを計算するだけでTrue率が求められる\n",
    "accuracy = np.mean(prediction_result)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4exDtcylRJwE"
   },
   "source": [
    "　さて、決定木モデルは、学習したモデルを画像で出力することができる。\n",
    "graphvizというツールの形式で出力されるため、`dot`というコマンドでPNG画像に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZHaYdhBNDBjy"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(model_full, out_file = \"tree_full.dot\", \n",
    "                     feature_names = X.columns,               # 特徴量名を表示させる\n",
    "                     impurity = False,                        # 表示を簡単にする\n",
    "                     class_names = [\"Died\", \"Survive\"])       # 予測結果をで表示させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KzKhmCAoDOgx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: dot: can't open #\n",
      "Error: dot: can't open これで画像ファイルが作成できる\n"
     ]
    }
   ],
   "source": [
    "# graphvizを使ってpngなどに変換するおまじない、Google Colabでは最初から入っている\n",
    "!dot -Tpng tree_full.dot -o tree_full.png # これで画像ファイルが作成できる\n",
    "# 左のペインのファイルからダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5Ebcxz_Ri1V"
   },
   "source": [
    "　ファイルをダウンロードして、閲覧してみよう。**図3.3**のような（とんでもない）図が作成されているはずだ。\n",
    "このように、一番上の部分から左右に2分割され続ける構造を「二分木」と言う。最初にも述べたが、scikit-learn の決定木は必ず二分木となる。\n",
    "\n",
    "![図3.3](https://i.imgur.com/2VSkFzS.png)\n",
    "\n",
    "**図3.3** 今回作成された決定木\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwOKk_jz4sil"
   },
   "source": [
    "-------\n",
    "##### 課題 DS3.1\n",
    "　先ほどは訓練データX_trainを使って、y_trainを予測した。\n",
    "\n",
    "　同様にテストデータX_testの予測を行い、y_testとの比較を行うことで、予測正解率を**百分率で小数点以下2桁を四捨五入し、小数点以下1桁まで**答えよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "69Bq8vpL4sVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.9 %\n"
     ]
    }
   ],
   "source": [
    "## ヒントコード\n",
    "pred_y_test = model_full.predict(X_test)\n",
    "prediction_result_test = (pred_y_test == y_test)\n",
    "accuracy_test = np.mean(prediction_result_test)\n",
    "print(\"%.1f\" % (accuracy_test*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzYbmM4b5UOs"
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2D95P5IXaVr"
   },
   "source": [
    "### DS3.1.2 | よりシンプルな決定木の構築\n",
    "\n",
    "　DS3.1.1で作成した決定木は非常に複雑であった。今度は、決定木の深さ（縦方向の大きさ）を制限することで、もっと簡単な決定木を作ってみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNqURi5mUI6i"
   },
   "source": [
    "　決定木の深さはモデルの引数で制限することが可能である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Hq1-kIgGUcvM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple = DecisionTreeClassifier(max_depth=3, random_state=0) # 最大深さを3に制限する\n",
    "model_simple.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geOJIltib3Ug"
   },
   "source": [
    "　model_fullの時と同様に、木構造を画像にしてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1WaVbpxdNBA_"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(model_simple, out_file = \"tree_simple.dot\", \n",
    "                     feature_names = X.columns, \n",
    "                     impurity = False, \n",
    "                     class_names = [\"Died\", \"Survive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JUHSJ7oSNEYM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: dot: can't open #\n",
      "Error: dot: can't open これで画像ファイルが作成できる\n"
     ]
    }
   ],
   "source": [
    "# graphvizを使ってpngなどに変換、Google Colabでは最初から入っている\n",
    "!dot -Tpng tree_simple.dot -o tree_simple.png # これで画像ファイルが作成できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6L2eQoF1O2Hk"
   },
   "source": [
    "　`tree_simple.png` も画像ファイルを開いて目視してみよう。\n",
    "こちらは木の深さ（一番上から一番したまでの経路の長さ）が3に制限されているので、比較的わかりやすい図になっている。\n",
    "\n",
    "![図3.4](https://i.imgur.com/aZCijPb.png)\n",
    "**図3.4** 深さを制限した決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPtcY-C4ayRp"
   },
   "source": [
    "------\n",
    "##### 課題 DS3.2\n",
    "\n",
    "　**図3.4**の決定木を言葉で表現してみよう。例えば、一番下の段、右から4番目は「男性で、年齢が14才以下で、1等室か2等室の乗客は11人中11人生存している」という意味である。\n",
    "\n",
    "　**一番下の段、左から3番目**について、「～～で、～～～で、～～～～の乗客は92人中57人生存している」と文章で記述せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-25-7e4565fea43e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-7e4565fea43e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    一番下の段、左から3番目について、「女性で、1等室と2等室以外で、船賃が23.35以下の乗客は92人中57人生存している」と文章で記述せよ。\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "一番下の段、左から3番目について、「女性で、1等室と2等室以外で、船賃が23.35以下の乗客は92人中57人生存している」と文章で記述せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G54XqdrnK_pt"
   },
   "source": [
    "------\n",
    "##### 課題 DS3.3\n",
    "\n",
    "　以下のコードの`__xxxxx__` 、`__yyyyy__` 、`__zzzzz__` を埋めて、確かに条件に該当する人が92人いることを確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JKGWGSU6LPyC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__xxxxx__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0b56e3ed292a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__xxxxx__\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mselection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__yyyyy__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mselection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__zzzzz__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__xxxxx__' is not defined"
     ]
    }
   ],
   "source": [
    "selection = X_train[__xxxxx__ <= 0.5]\n",
    "selection = selection[__yyyyy__]\n",
    "selection = selection[__zzzzz__]\n",
    "print(len(selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "selection  = X_train[X_train['Sex'] <= 0.5]\n",
    "selection = selection[selection['Pclass'] >= 2.5]\n",
    "selection = selection[selection['Fare'] < 23.35]\n",
    "print(len(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOxxW5S9Jvhy"
   },
   "source": [
    "------\n",
    "##### 課題 DS3.4\n",
    "\n",
    "　`model_simple` について、訓練データ `X_train` 、`y_train` に対して予測を行った時の正解率を計算し、訓練データに対する正解率は、 `model_full` と `model_simple` どちらの方が高いか述べよ。\n",
    "\n",
    "　同様にテストデータ `X_test` 、`y_test` に対して予測を行った場合は、 `model_full` と `model_simple` どちらの方が正解率が高いか答えよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ヒントコード\n",
    "pred_y_test = model_full.predict(X_test)\n",
    "prediction_result_test = (pred_y_test == y_test)\n",
    "accuracy_test = np.mean(prediction_result_test)\n",
    "print(\"%.1f\" % (accuracy_test*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.7 %\n"
     ]
    }
   ],
   "source": [
    "pred_y_train_simple = model_simple.predict(X_train)\n",
    "prediction_result_train_simple = (pred_y_train_simple == y_train)\n",
    "accuracy_train_simple = np.mean(prediction_result_train_simple)\n",
    "print('%.1f' % (accuracy_train_simple*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0 %\n"
     ]
    }
   ],
   "source": [
    "pred_y_test_simple = model_simple.predict(X_test)\n",
    "prediction_result_test_simple = (pred_y_test_simple == y_test)\n",
    "accuracy_test_simple = np.mean(prediction_result_test_simple)\n",
    "print('%.1f' % (accuracy_test_simple*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzUXihhShMZz"
   },
   "source": [
    "------------\n",
    "\n",
    "### DS3.1.3 | 交差検証法 (cross validation) を用いた2つのモデルの評価 (model assessment)\n",
    "\n",
    "　課題DS3.4は、「訓練データに対する正解率」と「テストデータに対する正解率」それぞれを比較する問題であったが、どちらの方が重要だろうか。\n",
    "\n",
    "　講義でも学んだように、母集団 (population) に対する平均的な予測精度（これを**汎化性能 (generalization performance)** と呼ぶ）が**高い方が利用価値の高い**モデルであるはずであり、**テストデータに対する性能で汎化性能を推定**している。\n",
    "つまり、**「テストデータに対する正解率」でモデルを比較すべきである**。\n",
    "\n",
    "　さらに、データのtraining-test分割を複数通り試すことで、**汎化性能を高精度に推定**することができる。その際に最も広く用いられるのが **$k$-分割交差検証法（$k$-fold cross validation, $k$-fold CV）**である。$k$-分割交差検証法では、**図3.4**のように、学習データを $k$ 個に分割（図の例では $k=4$ ）して、 $k-1$ 個のグループを学習用データに、1個のグループをテスト用データにした時の汎化性能を $k$ 回求め、その平均値（と標準偏差）でモデルの性能を評価する。また、$k$がデータ数と同じ場合（つまり、一つのデータをテスト\n",
    "データにする場合）を特に**一個抜き交差検証法（leave-one-out cross validation, LOOCV）**という。\n",
    "\n",
    "![図3.5](https://i.imgur.com/AUMBdH0.png)\n",
    "\n",
    "**図3.5** 交差検証法 (cross validation) のデータ分割イメージ。4-fold 交差検証法を図示している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-pSHQ6wVBLt"
   },
   "source": [
    "　scikit-learnでは、交差検証法も `cross_val_score()` を用いることで簡単に実行することができる。関数の中でデータ分割を行うため、**`cross_val_score()` には全データを与える**ことに注意しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "oYHEZDZZPHAB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7710611735330836 +- 0.04461559297960239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "model_full = DecisionTreeClassifier(random_state=0)\n",
    "full_cv_scores = cross_val_score(model_full, X, y, cv=10)\n",
    "print(np.mean(full_cv_scores), \"+-\", np.std(full_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eP9GkZOQwVJw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8136953807740325 +- 0.02804063097059579\n"
     ]
    }
   ],
   "source": [
    "model_simple = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "simple_cv_scores = cross_val_score(model_simple, X, y, cv=10)\n",
    "print(np.mean(simple_cv_scores), \"+-\", np.std(simple_cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ytfzTl9V-eO"
   },
   "source": [
    "　この結果から、木の深さを制限した決定木 `model_simple`の方が正解率が十分に高いことがわかる（**補足資料 ※2**）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oZWGO-kcDK_"
   },
   "source": [
    "## DS3.2 | モデル選択 (model selection)\n",
    "\n",
    "　DS3.1で、木の深さを制限した方が汎化性能が高いことが分かったが、ここでは**予測精度を最大化する最適な決定木の最大深さを探してみる**。このように、複数の学習モデルから最良のモデルを選ぶことを**モデル選択 (model selection)** と呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43k0wn71xCl7"
   },
   "source": [
    "### DS3.2.1 | training-validation-test 分割\n",
    "\n",
    "　講義で学んだように、モデル選択（例：決定木における「木の最大深」の最適化）においては、汎化性能を正しく推定するために訓練データ (training data) 、**検証データ (validation data)** 、テストデータ (test data) の3データに分割した上で、以下の手順を踏む（**補足資料 ※3**）。\n",
    "\n",
    "* **モデル選択 (model selection)** ：検証データ (validation data) を最もよく予測できるモデルを選ぶ\n",
    "* **モデルの評価 (model assessment)** ：最良モデルを使ってテストデータ (test data) を予測し、汎化性能を推定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXIf9ljSYJJ0"
   },
   "source": [
    "### DS3.2.2 | 交差検証法を用いたモデルの選択\n",
    "　それでは、DS3.1節でも用いた交差検証法を用いて、決定木の深さの最大値はいくつにするのが最も良さそうか、確かめてみよう（このように、学習を行う前に指定しなければならない変数のことを**ハイパーパラメータ**と呼ぶ）。\n",
    "\n",
    "　この場合、**テストデータはあらかじめ除外した上で、訓練データと検証データの分割を交差検証法によって複数回試す**のが良い（**図3.6**）。\n",
    "\n",
    "![図3.6](https://i.imgur.com/2i5U90o.png)\n",
    "\n",
    "**図3.6** モデル選択時の交差検証法 (cross validation) のデータ分割イメージ。20%をテストデータにしたうえで、4-fold 交差検証法を行った場合を図示している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx3tw45K2boL"
   },
   "source": [
    "　**図3.6**のデータ分割を実現するには、まず`train_test_split()` を行い、`X_train`, `y_train`, `X_test`, `y_test`に分割した上で、`X_train`と`y_train`をつかって交差検証法を行えばよい。\n",
    "\n",
    "　ハイパーパラメータの探索時には交差検証法は極めてよく利用されるため、scikit-learnでは `GridSearchCV()` 関数が用意されている。以下では、これを用いて最適なハイパーパラメータを探索している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ac3dtbyc4YPe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "# test_size=0.2とすることで、全データの20%をテストデータにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Z3vF0ntxbP_u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n",
      "0.8104655712050078\n"
     ]
    }
   ],
   "source": [
    "# 辞書型が1つ入った配列\n",
    "param_grid = [  \n",
    "  {\n",
    "    \"max_depth\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "  }\n",
    "]\n",
    "template_model = DecisionTreeClassifier(random_state=0)          # 未学習の決定木を準備する\n",
    "grid_search_dt = GridSearchCV(template_model, param_grid, cv=10) # 10-fold CVをしながら最適なモデルを決定する、という指令を与える\n",
    "grid_search_dt.fit(X_train, y_train)                             # 実際にデータを与え、内部でtraining-validation分割を行いながら最適なモデルを決定する\n",
    "print(grid_search_dt.best_params_)                               # 最適なハイパーパラメータを確認する\n",
    "print(grid_search_dt.best_score_)                                # 最適なハイパーパラメータの時のvalidationセットの予測精度を表示する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBMJ9_9zcYV4"
   },
   "source": [
    "　この結果から、titanicデータに対する予測では、木の深さの最大値を4にした時に最も正解率が高くなることがわかった。新しいデータを予測する時には、このモデルを使うと良さそうだ。\n",
    "\n",
    "　最後に、このモデルでテストデータを予測することで、汎化性能を推定しよう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "u_i6AGNz4wAA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "pred_y_test = grid_search_dt.predict(X_test)\n",
    "prediction_result = (y_test == pred_y_test)\n",
    "accuracy = np.mean(prediction_result)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsI9B7CO4woX"
   },
   "source": [
    "　以上で、交差検証法を用いたモデル選択を行い、最良モデルの汎化性能を推定することができた（**補足資料 ※4**）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6K3raw-10um"
   },
   "source": [
    "　今回の授業では、2種類の交差検証法 cross validation の説明を行ったが、どう使い分ければよいか理解できただろうか。**自分が作ることのできる「学習器とハイパーパラメータの組み合わせ」が複数あるなら、trainとvalidationを使って自分の最強モデルを決め**、**他人の手法と比較するときはtestデータを使って比較する**と考えておくと良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JmXKwjkQ81T"
   },
   "source": [
    "--------\n",
    "\n",
    "##### 課題 DS3.5\n",
    "\n",
    "　講義資料では、決定木の最大深さのみをいろいろ変化させて評価したが、これに加えて、`min_samples_leaf`という値も`1,2,3,4,5,6,7,8,9,10`の値の範囲で探索したい。\n",
    "\n",
    "　まず、**min_samples_leafとはどういうパラメータか調べ、簡潔に答えよ**。\n",
    "\n",
    "　次に、GridSearchCVを用いて、min_samples_leafも含めたパラメータ探索を行い、最良のモデルのmax_depthとmin_samples_leafの値、およびテストデータ予測時の正解率を答えよ。正解率は**百分率で小数点以下2桁目を四捨五入し、小数点以下1桁まで**答えること。\n",
    "\n",
    "なお、実行結果の再現性を担保するため、`random_state` が記述された以下のコードを使用せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "uAgi2AlcNUqm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.8 %\n"
     ]
    }
   ],
   "source": [
    "# データの生成\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 探索するパラメータの設定\n",
    "param_grid_2 = [\n",
    "    {\n",
    "        \"min_samples_leaf\": [x for x in range(1,11)]\n",
    "    }\n",
    "]\n",
    "\n",
    "#10-fold CVをしながら最適なモデルを決定\n",
    "grid_search_dt2 = GridSearchCV(DecisionTreeClassifier(random_state = 0),param_grid_2,cv = 10)\n",
    "grid_search_dt2.fit(X_train,y_train)\n",
    "\n",
    "# テストデータを用いた評価\n",
    "\n",
    "pred_y_test_leaf = grid_search_dt2.predict(X_test)\n",
    "pred_y_test_leaf_result = (pred_y_test_leaf == y_test)\n",
    "min_leaf_accuracy = np.mean(pred_y_test_leaf_result)\n",
    "\n",
    "print(\"%.1f\" % ((min_leaf_accuracy)*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1byFIoSEUnpi"
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37DMY818jzZy"
   },
   "source": [
    "# レポート提出について\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLzUiGyLXOdo"
   },
   "source": [
    "## レポートの提出方法\n",
    "\n",
    "　レポートは**答案テンプレートを用い**、**1つのファイル（.doc, .docx, .pdf）**にまとめ、**学籍番号と氏名を確認の上**、**次回 基盤データサイエンス演習 の開始時刻までに東工大ポータルのOCW-iから提出**すること。\n",
    "ファイルのアップロード後、OCW-iで「提出済」というアイコンが表示されていることを必ず確認すること。それ以外の場合は未提出扱いとなるので十分注意すること。\n",
    "また、締め切りを過ぎるとファイルの提出ができないため、時間に余裕を持って提出を行うこと。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z6NkAX-3IQG"
   },
   "source": [
    "## 答案テンプレート\n",
    "\n",
    "```\n",
    "学籍番号:\n",
    "名前:\n",
    "\n",
    "課題 DS3.1\n",
    "テストデータに対する正解率： ______ %\n",
    "\n",
    "課題 DS3.2\n",
    "____________で、____________で、____________の乗客は92人中57人生存している。\n",
    "\n",
    "課題 DS3.3\n",
    "__xxxxx__ = _________________\n",
    "__yyyyy__ = _________________\n",
    "__zzzzz__ = _________________\n",
    "\n",
    "課題 DS3.4\n",
    "訓練データに対する正解率は、 { model_full | model_simple } の方が良い。\n",
    "テストデータに対する正解率は、 { model_full | model_simple } の方が良い。\n",
    "\n",
    "課題 DS3.5\n",
    "min_samples_leafとは：\n",
    "\n",
    "最良モデルのmax_depth：\n",
    "最良モデルのmin_samples_leaf：\n",
    "最良モデルのテストデータ正解率： _____ %\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-aFt0WYsfl_"
   },
   "source": [
    "## 補足資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1IuOlt1xA2n"
   },
   "source": [
    "### ※1 データクレンジングの重要性\n",
    "\n",
    "　データサイエンスを行う場合、第2回の講義で利用したirisのように全てのデータが完全に埋まっていることはあまり多くなく、記載されている情報すら誤りが含まれている。\n",
    "\n",
    "　例えば、欠損は以下のようなときに発生する。\n",
    "* 必須登録項目ではない\n",
    "  * 例：SNSにおける生年月日\n",
    "* 選択肢に「不明」が含まれる\n",
    "  * 例：性別（LGBT等への配慮）\n",
    "\n",
    "　また、情報の誤りは以下のケースが考えられる。\n",
    "* 意図的な虚偽申告\n",
    "  * 例：小学生のtwitter利用（現在twitterは13才以下利用禁止）\n",
    "  * 例：1人暮らし女性などの通販サイトの「男性」としての登録（防犯上の理由）\n",
    "* 初期設定が原因である虚偽申告\n",
    "  * 都道府県（初期設定が北海道で、変更せずそのまま登録）\n",
    "* 複数人が同一アカウントを利用している\n",
    "  * 母親のアカウントで家族全員分の通販を処理\n",
    "  \n",
    "　このため、ユーザが自己申告する情報を鵜呑みにせず、購入履歴などから情報を推定することも重要になったりする。\n",
    "\n",
    "　また、機械的なものであっても、センサーの不具合や故障によって、欠測や誤った計測値の出力は発生するため、こちらもやはり前後のデータから誤りが発生していないか判定することが必要になる。\n",
    "\n",
    "　これらのデータの「汚れ」をキレイにすることは**極めて重要**であり、かつ極めて地味な作業でもある。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYTRmGv4W0fY"
   },
   "source": [
    "### ※2 model_simpleはmodel_fullよりも「有意」に汎化性能が高いのか？\n",
    "\n",
    "　model_simpleの方がmodel_fullよりも予測精度の平均が高いことが分かったが、これは偶然なのだろうか、それとも有意に差があるのだろうか。ウィルコクソンの符号順位検定を行うことで、model_simpleがmodel_fullに勝っているかどうか統計的に評価してみよう。\n",
    "\n",
    "\n",
    "　ここでは、帰無仮説を「model_simpleの汎化性能はmodel_fullの汎化性能よりも高くない」、有意水準を$\\alpha=0.05$とする。\n",
    "ウィルコクソンの符号順位検定は、SciPyというパッケージを利用することで行うことが出来る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "C_CQW2fDYgcS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=7.5, pvalue=0.0185546875)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "model_full = DecisionTreeClassifier(random_state=0)\n",
    "model_simple = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "full_cv_scores = cross_val_score(model_full, X, y, cv=10)\n",
    "simple_cv_scores = cross_val_score(model_simple, X, y, cv=10)\n",
    "\n",
    "\n",
    "print(stats.wilcoxon(full_cv_scores, simple_cv_scores, alternative=\"less\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mn4Kb8cBZR7H"
   },
   "source": [
    "　`pvalue=0.0294...`という結果より、帰無仮説が棄却され、model_simpleはmodel_fullに有意に汎化性能が高いことが示された。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vorR4Qem05uv"
   },
   "source": [
    "### ※3 なぜtraining-validation-test分割は必要か？\n",
    "\n",
    "　講義でもtraining-validation-test分割の必要性の議論はあったと思うのだが、一応ここでも補足資料として記載しておくことにする。\n",
    "\n",
    "　こんなことを考えてみよう。世界で数学選手権が行われ、日本でその国内予選がある。競技参加者は同じ参考書を使って勉強し、国内予選に出場し、そこで最も良い成績を収めた選手1名が日本代表として世界大会で各国の代表と競う。\n",
    "\n",
    "　国内予選では問題セット $V$ が出題されたとすると、総合的な実力もさることながら、たまたま $V$ が得意な問題だった選手は良い成績を収めやすい。しかし、世界大会で出題される問題セット $T$ は問題セット $V$ とは異なる問題なので、もし難易度が全く一緒だったとしても、国内予選よりもわずかに悪い成績に落ち着く可能性が高いだろう。\n",
    "\n",
    "　関係性がわかっただろうか。**多数の国内予選出場者が多数のモデルに対応**し、予選出場者の**参考書が訓練データ**、**国内予選の問題セット $V$ が検証データ**、**世界大会の問題セット $T$ がテストデータ**である。モデル選択によってえらばれた代表モデルは**検証データを予測するのが得意だったから**選ばれた可能性があり、**汎化性能（任意の問題に対する成績の期待値）よりも高いことが多い**のである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vLjKNfIwEQz"
   },
   "source": [
    "### ※4 検証データよりもテストデータの予測精度が良くなっている？\n",
    "\n",
    "　補足資料 ※3 で議論したように、一般的にはモデル選択を行うとわずかに**検証データの方がテストデータよりも予測精度が高くなる**はずである。しかし、実際に `GridSearchCV()` を使って、検証データ、テストデータに対する予測精度をそれぞれ眺めてみると、テストデータに対する予測精度の方がわずかに高いことがある。なぜだろうか？\n",
    "\n",
    "　これは、scikit-learnの`GridSearchCV()`が、\n",
    "\n",
    "* 訓練データで学習を行いながら、最適なハイパーパラメータを探索する\n",
    "* 最適なハイパーパラメータを用いて、**訓練データ+検証データで学習を行う**\n",
    "\n",
    "という動作を行うためである。学習に用いられるデータ数が多くなることで、テストデータの予測精度が向上している可能性がある。\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS3_Classification_and_ModelEvaluation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
